### token:
Tokens are the basic units of data processed by LLMs. In the context of text, a token can be a word, part of a word (subword), or even a character — depending on the tokenization process.
在語言模型中,「token」指的是文本的基本單位。

### protocols:
- download the tokenizer model (according to the model you want to use)
- select the json file that you want to count tokens in.
- run token_counter.py
